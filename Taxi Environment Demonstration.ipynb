{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## Variations on the Taxi-Grid Enviroment\n",
    "    \n",
    "    ### Single Taxi With Fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will demonstrate the most basic enviroment - one taxi with fuel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: |F: :G|\n",
      "| : | :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "Fuel: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onetaxifuel_env import OneTaxiFuelEnv\n",
    "env = OneTaxiFuelEnv()\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaxiFuelEnv is an enviroment where there is one taxi. The taxi is represented by the yellow highlighted block. The objective of the taxi in this enviroment is to move the passenger from the blue Y to the magenta R. The action space of the taxi is (0,1,2,3,4,5,6), where 0,1,2,3 are respectively move south, north, east, west, 4 is pickup passenger, 5 is dropoff passenger, and 6 is refuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next state is: 1858, the reward for the last action is: -10, and the episode is not done.\n"
     ]
    }
   ],
   "source": [
    "state, reward, done, _ = env.step(6)\n",
    "print(\"The next state is: \" + str(state) + \", the reward for the last action is: \" + str(reward) + \", and the episode is \"+ {True: \"\", False: \"not\"}[done]  + \" done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preform an action, we use the step function. This returns a tuple which is the next state, which includes the value of the next state, the reward, which is -10, corresponding to the reward , and whether the episode has ended, which is False, since the episode ends when the taxi has dropped off the passenger. Now, we will navigate to the fuel station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: |\u001b[43mF\u001b[0m: :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "Fuel: 8\n",
      "  (West)\n"
     ]
    }
   ],
   "source": [
    "env.step(1)\n",
    "env.step(3)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, note that since we have moved two steps, we have consumed two units of fuel. There is a large penalty for moving when the taxi does not have fuel. We will now refuel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: |\u001b[43mF\u001b[0m: :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "Fuel: 10\n",
      "  (Refill)\n"
     ]
    }
   ],
   "source": [
    "state, reward, done, _ = env.step(6)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, since we have refuelled, we are back at full. Another thing to note is that the state of the enviroment is encoded using a single number that represents the state. However, sometimes it may be useful to decode what that number actually means (for example, when using deep-Q learning). We can do that using the decode function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coordinates of the taxi are currently: (0,2)\n",
      "The index of the passenger location is: 2, while the index of the passenger destination is: 0\n",
      "Currently, the fuel level of the taxi is 10\n"
     ]
    }
   ],
   "source": [
    "x, y, pass_loc, pass_dest, fuel = list(env.decode(state))\n",
    "print(\"The coordinates of the taxi are currently: \" + \"(\" + str(x) + \",\" + str(y) +\")\")\n",
    "print(\"The index of the passenger location is: \" + str(pass_loc) + \", while the index of the passenger destination is: \" + str(pass_dest))\n",
    "print(\"Currently, the fuel level of the taxi is: \" + str(fuel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the demonstration for the single taxi with fuel environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple taxi with fuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most sophisticated enviroment is the multiple taxi with fuel environment. This environment supports an arbitrary number of taxis with fuel and an arbitrary number of passengers. By default, the enviroment is initialized with two taxis, one passenger, and the maximum (and starting) fuel of each taxi is 8. However, we are able to change all of those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|X: |F: :\u001b[35mX\u001b[0m|\n",
      "| :\u001b[43m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | :\u001b[41m_\u001b[0m| : |\n",
      "|\u001b[34;1mX\u001b[0m| :G|\u001b[35m\u001b[34;1mX\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "Taxi1: Fuel: 8, Location: (1,1)\n",
      "Taxi2: Fuel: 8, Location: (3,2)\n",
      "Passenger1: Location: (4, 3), Destination: (0, 4)\n",
      "Passenger2: Location: (4, 0), Destination: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "from multitaxifuel_env import MultiTaxiFuelEnv\n",
    "env = MultiTaxiFuelEnv(num_taxis = 2, num_passengers = 2, max_fuel = 8)\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the enviroment, we have the location and fuel values for each of the passneger, as well as the location and destination values for each passenger. In the multiple passenger enviroment, the episode does not end until each passenger is delivered to their destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 1], [3, 2]], [8, 8], [[4, 3], [4, 0]], [[0, 4], [4, 3]], [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(env.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, note that the enviroment, rather than being stored as a single number, is instead stored as a list. Also, since there are multiple taxis, we will now preform a joint action, which will be returned as a list. The actions for each individual taxi are the same as in the original taxi fuel enviroment. For example, suppose that I wish for taxi 1 to go north (action 1) and for taxi 2 to go south (action 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the reward is given as the reward for each individual taxi: [-1, -1]\n",
      "+---------+\n",
      "|X:\u001b[43m_\u001b[0m|F: :\u001b[35mX\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mX\u001b[0m| :\u001b[41mG\u001b[0m|\u001b[35m\u001b[34;1mX\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (North ,South)\n",
      "Taxi1: Fuel: 7, Location: (0,1)\n",
      "Taxi2: Fuel: 7, Location: (4,2)\n",
      "Passenger1: Location: (4, 3), Destination: (0, 4)\n",
      "Passenger2: Location: (4, 0), Destination: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "state, reward, done, _ = env.step([1,0])\n",
    "print(\"Now the reward is given as the reward for each individual taxi: \" + str(reward))\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try a random solution, and see how long it takes to finish an episode. In particular, at every time step, each of the taxis will choose a random action. We can easily do this using the env.action_space.sample() function, which returns a random sample of the action space corresponding to a random action by each taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 11487\n",
      "Penalties incurred: 11392\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "\n",
    "frames = [] # for animation\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    if reward[0] == -10 or reward[1] == -10:\n",
    "        penalties += 1\n",
    "    \n",
    "    # Put each rendered frame into dict for animation\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epochs += 1\n",
    "    \n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, as we have seen, the episode takes a very long time to finish, and the taxis incur many penalties, meaning that they have tried many invalid moves. We can see this in action by replaying the frames of that episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[35mX\u001b[0m\u001b[0m: |F: :\u001b[43mX\u001b[0m|\n",
      "| : | : :\u001b[34;1m \u001b[0m|\n",
      "| : : : : |\n",
      "|\u001b[34;1m \u001b[0m| : | : |\n",
      "|\u001b[41mX\u001b[0m| :G|X: |\n",
      "+---------+\n",
      "  (Pickup ,Pickup)\n",
      "Taxi1: Fuel: 0, Location: (0,4)\n",
      "Taxi2: Fuel: 0, Location: (4,0)\n",
      "Passenger1: Location: (1, 4), Destination: (0, 0)\n",
      "Passenger2: Location: (3, 0), Destination: (0, 0)\n",
      "\n",
      "Timestep: 2673\n",
      "State: [[[4, 0], [0, 0]], [0, 0], [[1, 0], [2, 2]], [[0, 0], [0, 0]], [-1, -1]]\n",
      "Action: [4 4]\n",
      "Reward: [-10, -10]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(.1)\n",
    "        \n",
    "print_frames(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
